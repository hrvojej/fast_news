
I'll provide the complete SQL code in logical chunks. Let's start with the core schema and table structures.

Part 1 - Core Schema and News Portals:

sql

Copy
-- Enable required extensions
CREATE EXTENSION IF NOT EXISTS ltree;

-- Create news_portals table
CREATE TABLE IF NOT EXISTS public.news_portals (
    portal_id SERIAL PRIMARY KEY,
    portal_prefix VARCHAR(50) NOT NULL UNIQUE,
    name VARCHAR(255) NOT NULL,
    base_url TEXT NOT NULL,
    rss_url TEXT,
    scraping_enabled BOOLEAN DEFAULT true,
    portal_language VARCHAR(50),
    timezone VARCHAR(50) DEFAULT 'UTC',
    active_status BOOLEAN DEFAULT true,
    scraping_frequency_minutes INTEGER DEFAULT 60,
    last_scraped_at TIMESTAMPTZ,
    created_at TIMESTAMPTZ DEFAULT CURRENT_TIMESTAMP,
    updated_at TIMESTAMPTZ DEFAULT CURRENT_TIMESTAMP
);

-- Create indexes for news_portals
CREATE INDEX IF NOT EXISTS idx_portal_status ON public.news_portals(active_status);
CREATE INDEX IF NOT EXISTS idx_portal_prefix ON public.news_portals(portal_prefix);

-- Create update_updated_at_column function
CREATE OR REPLACE FUNCTION update_updated_at_column()
RETURNS TRIGGER AS $$
BEGIN
    NEW.updated_at = CURRENT_TIMESTAMP;
    RETURN NEW;
END;
$$ LANGUAGE plpgsql;

-- Create trigger for news_portals
CREATE TRIGGER update_news_portals_updated_at
    BEFORE UPDATE ON public.news_portals
    FOR EACH ROW
    EXECUTE FUNCTION update_updated_at_column();
Should I continue with the next part focusing on the dynamic schema creation for each portal?

 Copy
Retry


H
Yes


sql

Copy
-- Dynamic Schema Creation for Each Portal
DO $$ 
DECLARE
   portal RECORD;
BEGIN
   FOR portal IN SELECT portal_prefix FROM public.news_portals
   LOOP
       -- Create schema
       EXECUTE format('CREATE SCHEMA IF NOT EXISTS %I', portal.portal_prefix);

       -- Create categories table
       EXECUTE format('
           CREATE TABLE IF NOT EXISTS %I.categories (
               category_id SERIAL PRIMARY KEY,
               name VARCHAR(255) NOT NULL,
               slug VARCHAR(255) NOT NULL,
               portal_id INT NOT NULL REFERENCES public.news_portals(portal_id) ON DELETE CASCADE,
               path LTREE NOT NULL,
               level INT NOT NULL,
               title TEXT,
               link TEXT,
               atom_link TEXT,
               description TEXT,
               language VARCHAR(50),
               copyright_text TEXT,
               last_build_date TIMESTAMPTZ,
               pub_date TIMESTAMPTZ,
               image_title TEXT,
               image_url TEXT,
               image_link TEXT,
               keywords TEXT[],
               is_active BOOLEAN DEFAULT true,
               created_at TIMESTAMPTZ DEFAULT CURRENT_TIMESTAMP,
               updated_at TIMESTAMPTZ DEFAULT CURRENT_TIMESTAMP,
               UNIQUE(slug, portal_id)
           )', portal.portal_prefix);

       -- Create indexes for categories
       EXECUTE format('
           CREATE INDEX IF NOT EXISTS idx_category_path ON %I.categories USING GIST (path);
           CREATE INDEX IF NOT EXISTS idx_category_portal ON %I.categories(portal_id);
           CREATE INDEX IF NOT EXISTS idx_category_active ON %I.categories(is_active);
           CREATE INDEX IF NOT EXISTS idx_category_language ON %I.categories(language);
       ', portal.portal_prefix, portal.portal_prefix, portal.portal_prefix, portal.portal_prefix);

       -- Create articles table
       EXECUTE format('
           CREATE TABLE IF NOT EXISTS %I.articles (
               article_id SERIAL PRIMARY KEY,
               title TEXT NOT NULL,
               url TEXT NOT NULL,
               guid TEXT UNIQUE,
               description TEXT,
               content TEXT,
               author TEXT[],
               pub_date TIMESTAMPTZ,
               category_id INT NOT NULL REFERENCES %I.categories(category_id) ON DELETE CASCADE,
               keywords TEXT[],
               reading_time_minutes INTEGER,
               word_count INTEGER,
               language_code VARCHAR(10),
               image_url TEXT,
               image_width INTEGER,
               image_height INTEGER,
               image_alt_text TEXT,
               image_credit TEXT,
               sentiment_score FLOAT,
               sentiment_keywords TEXT[5],
               key_quotes TEXT[],
               share_count INTEGER DEFAULT 0,
               view_count INTEGER DEFAULT 0,
               comments_json JSONB,
               comment_count INTEGER DEFAULT 0,
               comment_sentiment_score FLOAT,
               comment_sentiment_keywords TEXT[10],
               video_urls TEXT[],
               video_transcripts TEXT[],
               created_at TIMESTAMPTZ DEFAULT CURRENT_TIMESTAMP,
               updated_at TIMESTAMPTZ DEFAULT CURRENT_TIMESTAMP,
               CONSTRAINT valid_sentiment_score CHECK (sentiment_score BETWEEN -1 AND 1)
           )', portal.portal_prefix, portal.portal_prefix);

       -- Create indexes for articles
       EXECUTE format('
           CREATE INDEX IF NOT EXISTS idx_articles_pub_date ON %I.articles(pub_date);
           CREATE INDEX IF NOT EXISTS idx_articles_sentiment ON %I.articles(sentiment_score);
           CREATE INDEX IF NOT EXISTS idx_articles_engagement ON %I.articles(share_count, view_count);
           CREATE INDEX IF NOT EXISTS idx_articles_search ON %I.articles USING gin(to_tsvector(''english'', title || '' '' || COALESCE(description,'''') || '' '' || COALESCE(content,'''')));
           CREATE INDEX IF NOT EXISTS idx_articles_keywords ON %I.articles USING gin(keywords);
           CREATE INDEX IF NOT EXISTS idx_articles_comments ON %I.articles USING gin(comments_json jsonb_path_ops);
       ', portal.portal_prefix, portal.portal_prefix, portal.portal_prefix, portal.portal_prefix, portal.portal_prefix, portal.portal_prefix);

       -- Create triggers for updated_at
       EXECUTE format('
           CREATE TRIGGER update_categories_updated_at
               BEFORE UPDATE ON %I.categories
               FOR EACH ROW
               EXECUTE FUNCTION update_updated_at_column();

           CREATE TRIGGER update_articles_updated_at
               BEFORE UPDATE ON %I.articles
               FOR EACH ROW
               EXECUTE FUNCTION update_updated_at_column();
       ', portal.portal_prefix, portal.portal_prefix);
   END LOOP;
END $$;
Should I continue with the Events schema?

 Copy
Retry


H
Yes


sql

Copy
-- Events Schema
CREATE SCHEMA IF NOT EXISTS events;

-- Events Table
CREATE TABLE IF NOT EXISTS events.events (
   event_id SERIAL PRIMARY KEY,
   title TEXT NOT NULL,
   description TEXT,
   start_time TIMESTAMPTZ NOT NULL,
   end_time TIMESTAMPTZ,
   is_ongoing BOOLEAN DEFAULT true,
   last_update_time TIMESTAMPTZ,
   event_type VARCHAR(50) NOT NULL,
   importance_level INT CHECK (importance_level BETWEEN 1 AND 5),
   geographic_scope VARCHAR(50),
   location_data JSONB,
   key_entities TEXT[],
   tags TEXT[],
   sentiment_score FLOAT CHECK (sentiment_score BETWEEN -1 AND 1),
   sentiment_keywords TEXT[5],
   view_count INTEGER DEFAULT 0,
   follower_count INTEGER DEFAULT 0,
   status VARCHAR(50) DEFAULT 'active' CHECK (status IN ('active', 'completed', 'archived', 'merged')),
   confidence_score FLOAT CHECK (confidence_score BETWEEN 0 AND 1),
   parent_event_id INTEGER REFERENCES events.events(event_id),
   created_at TIMESTAMPTZ DEFAULT CURRENT_TIMESTAMP,
   updated_at TIMESTAMPTZ DEFAULT CURRENT_TIMESTAMP
);

-- Event Articles Table
CREATE TABLE events.event_articles (
   event_id INT REFERENCES events.events(event_id) ON DELETE CASCADE,
   article_id INT NOT NULL,
   portal_id INT NOT NULL REFERENCES public.news_portals(portal_id),
   similarity_score FLOAT NOT NULL CHECK (similarity_score BETWEEN 0 AND 1),
   relevance_weight FLOAT CHECK (relevance_weight BETWEEN 0 AND 1),
   shared_entities TEXT[] NOT NULL DEFAULT '{}',
   shared_keywords TEXT[] NOT NULL DEFAULT '{}',
   context_summary TEXT,
   article_event_timestamp TIMESTAMPTZ NOT NULL DEFAULT CURRENT_TIMESTAMP,
   sequence_order INT,
   created_at TIMESTAMPTZ DEFAULT CURRENT_TIMESTAMP,
   PRIMARY KEY (event_id, article_id, portal_id)
);

-- Event Timeline Table
CREATE TABLE events.timeline_entries (
   entry_id SERIAL PRIMARY KEY,
   event_id INT REFERENCES events.events(event_id) ON DELETE CASCADE,
   article_id INT NOT NULL,
   portal_id INT NOT NULL REFERENCES public.news_portals(portal_id),
   entry_timestamp TIMESTAMPTZ NOT NULL,
   entry_type VARCHAR(50) NOT NULL CHECK (entry_type IN ('initial', 'update', 'development', 'conclusion')),
   significance_score FLOAT CHECK (significance_score BETWEEN 0 AND 1),
   summary TEXT NOT NULL,
   key_changes TEXT[],
   key_entities TEXT[],
   impact_level INT CHECK (impact_level BETWEEN 1 AND 5),
   sentiment_shift FLOAT,
   source_count INT DEFAULT 1,
   verification_status VARCHAR(50) DEFAULT 'unverified' CHECK (verification_status IN ('unverified', 'partially_verified', 'verified')),
   created_at TIMESTAMPTZ DEFAULT CURRENT_TIMESTAMP,
   updated_at TIMESTAMPTZ DEFAULT CURRENT_TIMESTAMP,
   CONSTRAINT unique_article_timeline UNIQUE(event_id, article_id, portal_id)
);

-- Create Indexes
CREATE INDEX idx_events_temporal ON events.events(start_time, end_time);
CREATE INDEX idx_events_status ON events.events(status);
CREATE INDEX idx_events_type ON events.events(event_type);
CREATE INDEX idx_events_importance ON events.events(importance_level);
CREATE INDEX idx_events_location ON events.events USING GIN (location_data);
CREATE INDEX idx_events_entities ON events.events USING GIN (key_entities);
CREATE INDEX idx_events_sentiment ON events.events(sentiment_score);

CREATE INDEX idx_event_articles_portal ON events.event_articles(portal_id);
CREATE INDEX idx_event_articles_similarity ON events.event_articles(similarity_score DESC);
CREATE INDEX idx_event_articles_temporal ON events.event_articles(article_event_timestamp);
CREATE INDEX idx_event_articles_entities ON events.event_articles USING GIN (shared_entities);
CREATE INDEX idx_event_articles_keywords ON events.event_articles USING GIN (shared_keywords);

CREATE INDEX idx_timeline_event ON events.timeline_entries(event_id);
CREATE INDEX idx_timeline_timestamp ON events.timeline_entries(entry_timestamp);
CREATE INDEX idx_timeline_significance ON events.timeline_entries(significance_score);
CREATE INDEX idx_timeline_type ON events.timeline_entries(entry_type);

-- Create Triggers
CREATE TRIGGER update_events_updated_at
   BEFORE UPDATE ON events.events
   FOR EACH ROW
   EXECUTE FUNCTION update_updated_at_column();

CREATE TRIGGER update_timeline_updated_at
   BEFORE UPDATE ON events.timeline_entries
   FOR EACH ROW
   EXECUTE FUNCTION update_updated_at_column();
Continue with Topics schema?

 Copy
Retry


H
Yes


sql

Copy
-- Topics Schema
CREATE SCHEMA IF NOT EXISTS topics;

-- Topic Categories
CREATE TABLE topics.topic_categories (
   category_id SERIAL PRIMARY KEY,
   name VARCHAR(255) NOT NULL,
   slug VARCHAR(255) NOT NULL UNIQUE,
   description TEXT,
   display_order INT,
   icon_class VARCHAR(50),
   status VARCHAR(50) DEFAULT 'active' CHECK (status IN ('active', 'inactive', 'archived')),
   created_at TIMESTAMPTZ DEFAULT CURRENT_TIMESTAMP,
   updated_at TIMESTAMPTZ DEFAULT CURRENT_TIMESTAMP
);

-- Topics Table
CREATE TABLE topics.topics (
   topic_id SERIAL PRIMARY KEY,
   category_id INT REFERENCES topics.topic_categories(category_id),
   name VARCHAR(255) NOT NULL,
   slug VARCHAR(255) NOT NULL,
   description TEXT,
   parent_topic_id INT REFERENCES topics.topics(topic_id),
   path LTREE NOT NULL,
   level INT NOT NULL,
   root_topic_id INT REFERENCES topics.topics(topic_id),
   keywords TEXT[],
   key_entities TEXT[],
   related_concepts TEXT[],
   sentiment_score FLOAT,
   sentiment_keywords TEXT[5],
   importance_score FLOAT CHECK (importance_score BETWEEN 0 AND 1),
   trending_score FLOAT,
   event_count INT DEFAULT 0,
   article_count INT DEFAULT 0,
   comment_count INT DEFAULT 0,
   view_count INT DEFAULT 0,
   follower_count INT DEFAULT 0,
   status VARCHAR(50) DEFAULT 'active' CHECK (status IN ('active', 'merged', 'split', 'archived')),
   visibility VARCHAR(50) DEFAULT 'public' CHECK (visibility IN ('public', 'private', 'archived')),
   first_appearance_date TIMESTAMPTZ,
   last_activity_at TIMESTAMPTZ,
   peak_activity_date TIMESTAMPTZ,
   created_at TIMESTAMPTZ DEFAULT CURRENT_TIMESTAMP,
   updated_at TIMESTAMPTZ DEFAULT CURRENT_TIMESTAMP,
   UNIQUE(slug, path),
   CONSTRAINT valid_hierarchy CHECK (
       (parent_topic_id IS NULL AND level = 1) OR 
       (parent_topic_id IS NOT NULL AND level > 1)
   )
);

-- Topic Relationships
CREATE TABLE topics.topic_relationships (
   source_topic_id INT REFERENCES topics.topics(topic_id),
   target_topic_id INT REFERENCES topics.topics(topic_id),
   relationship_type VARCHAR(50) NOT NULL CHECK (
       relationship_type IN (
           'parent_child', 'related', 'merged_into', 'split_from',
           'prerequisite', 'successor', 'contains', 'overlaps'
       )
   ),
   strength FLOAT CHECK (strength BETWEEN 0 AND 1),
   bidirectional BOOLEAN DEFAULT false,
   start_date TIMESTAMPTZ,
   end_date TIMESTAMPTZ,
   created_at TIMESTAMPTZ DEFAULT CURRENT_TIMESTAMP,
   PRIMARY KEY (source_topic_id, target_topic_id, relationship_type),
   CHECK (source_topic_id != target_topic_id)
);

-- Topic Timeline
CREATE TABLE topics.topic_timeline (
   timeline_id SERIAL PRIMARY KEY,
   topic_id INT REFERENCES topics.topics(topic_id),
   event_type VARCHAR(50) NOT NULL CHECK (
       event_type IN (
           'created', 'updated', 'merged', 'split',
           'archived', 'trending', 'significant_update'
       )
   ),
   event_date TIMESTAMPTZ NOT NULL,
   event_description TEXT,
   importance_score FLOAT CHECK (importance_score BETWEEN 0 AND 1),
   metadata JSONB,
   created_at TIMESTAMPTZ DEFAULT CURRENT_TIMESTAMP
);

-- Topic Statistics
CREATE TABLE topics.topic_statistics (
   topic_id INT REFERENCES topics.topics(topic_id),
   date_bucket DATE NOT NULL,
   article_count INT DEFAULT 0,
   event_count INT DEFAULT 0,
   comment_count INT DEFAULT 0,
   view_count INT DEFAULT 0,
   sentiment_score FLOAT,
   trending_score FLOAT,
   peak_hour_activity INT[],
   created_at TIMESTAMPTZ DEFAULT CURRENT_TIMESTAMP,
   PRIMARY KEY (topic_id, date_bucket)
);

-- Topic Content Mapping
CREATE TABLE topics.topic_content (
   topic_id INT REFERENCES topics.topics(topic_id) ON DELETE CASCADE,
   content_type VARCHAR(50) NOT NULL CHECK (
       content_type IN ('article', 'event', 'comment', 'social_post')
   ),
   content_id INT NOT NULL,
   portal_id INT REFERENCES public.news_portals(portal_id),
   relevance_score FLOAT CHECK (relevance_score BETWEEN 0 AND 1),
   sentiment_score FLOAT,
   assignment_type VARCHAR(50) DEFAULT 'automatic' CHECK (
       assignment_type IN ('automatic', 'manual', 'suggested')
   ),
   created_at TIMESTAMPTZ DEFAULT CURRENT_TIMESTAMP,
   PRIMARY KEY (topic_id, content_type, content_id)
);
Continue with indexes and triggers for Topics schema?

 Copy
Retry


H
Yes


sql

Copy
-- Indexes for Topics Schema
CREATE INDEX idx_topic_categories_status ON topics.topic_categories(status);
CREATE INDEX idx_topic_categories_display ON topics.topic_categories(display_order);

CREATE INDEX idx_topics_hierarchy ON topics.topics USING GIST (path);
CREATE INDEX idx_topics_parent ON topics.topics(parent_topic_id);
CREATE INDEX idx_topics_root ON topics.topics(root_topic_id);
CREATE INDEX idx_topics_status ON topics.topics(status, visibility);
CREATE INDEX idx_topics_trending ON topics.topics(trending_score DESC);
CREATE INDEX idx_topics_engagement ON topics.topics(view_count, comment_count);
CREATE INDEX idx_topics_temporal ON topics.topics(last_activity_at);
CREATE INDEX idx_topics_search ON topics.topics USING GIN (
   to_tsvector('english', 
       coalesce(name, '') || ' ' || 
       coalesce(description, '') || ' ' || 
       coalesce(array_to_string(keywords, ' '), '')
   )
);

CREATE INDEX idx_topic_relationships_type ON topics.topic_relationships(relationship_type);
CREATE INDEX idx_topic_relationships_temporal ON topics.topic_relationships(start_date, end_date);

CREATE INDEX idx_topic_timeline_date ON topics.topic_timeline(event_date);
CREATE INDEX idx_topic_timeline_type ON topics.topic_timeline(event_type);

CREATE INDEX idx_topic_stats_date ON topics.topic_statistics(date_bucket);
CREATE INDEX idx_topic_stats_trending ON topics.topic_statistics(trending_score);

CREATE INDEX idx_topic_content_type ON topics.topic_content(content_type);
CREATE INDEX idx_topic_content_relevance ON topics.topic_content(relevance_score);

-- Topic Path Update Function and Trigger
CREATE OR REPLACE FUNCTION topics.update_topic_path()
RETURNS TRIGGER AS $$
BEGIN
   IF NEW.parent_topic_id IS NULL THEN
       NEW.path = text2ltree(NEW.topic_id::text);
       NEW.level = 1;
       NEW.root_topic_id = NEW.topic_id;
   ELSE
       WITH RECURSIVE topic_path AS (
           SELECT topic_id, path, 1 as depth
           FROM topics.topics
           WHERE topic_id = NEW.parent_topic_id
           UNION ALL
           SELECT t.topic_id, t.path, p.depth + 1
           FROM topics.topics t
           JOIN topic_path p ON t.parent_topic_id = p.topic_id
       )
       SELECT 
           path || text2ltree(NEW.topic_id::text),
           depth + 1,
           topic_id
       INTO 
           NEW.path,
           NEW.level,
           NEW.root_topic_id
       FROM topic_path
       WHERE topic_id = NEW.parent_topic_id;
   END IF;
   RETURN NEW;
END;
$$ LANGUAGE plpgsql;

CREATE TRIGGER set_topic_path
   BEFORE INSERT OR UPDATE OF parent_topic_id
   ON topics.topics
   FOR EACH ROW
   EXECUTE FUNCTION topics.update_topic_path();

-- Topic Content Reference Validation
CREATE OR REPLACE FUNCTION topics.validate_topic_content_reference()
RETURNS TRIGGER AS $$
DECLARE
   portal_prefix TEXT;
BEGIN
   IF NEW.portal_id IS NOT NULL THEN
       SELECT portal_prefix INTO portal_prefix 
       FROM public.news_portals 
       WHERE portal_id = NEW.portal_id;
   END IF;

   CASE NEW.content_type
       WHEN 'article' THEN
           IF NEW.portal_id IS NULL THEN
               RAISE EXCEPTION 'portal_id is required for articles';
           END IF;
           EXECUTE format('SELECT 1 FROM %I.articles WHERE article_id = $1', portal_prefix) 
           USING NEW.content_id;
       WHEN 'event' THEN
           PERFORM 1 FROM events.events WHERE event_id = NEW.content_id;
       WHEN 'comment' THEN
           PERFORM 1 FROM comments.comments WHERE comment_id = NEW.content_id::text;
       WHEN 'social_post' THEN
           PERFORM 1 FROM social.posts WHERE post_id = NEW.content_id::text;
   END CASE;
   
   IF NOT FOUND THEN
       RAISE EXCEPTION '% ID % not found', NEW.content_type, NEW.content_id;
   END IF;
   RETURN NEW;
END;
$$ LANGUAGE plpgsql;

CREATE TRIGGER validate_topic_content_reference
   BEFORE INSERT OR UPDATE ON topics.topic_content
   FOR EACH ROW
   EXECUTE FUNCTION topics.validate_topic_content_reference();
Continue with Entities schema?

 Copy
Retry


H
Yes


sql

Copy
CREATE SCHEMA IF NOT EXISTS entities;

CREATE TABLE entities.entities (
   entity_id SERIAL PRIMARY KEY,
   name VARCHAR(255) NOT NULL,
   normalized_name VARCHAR(255) NOT NULL,
   entity_type VARCHAR(50) NOT NULL CHECK (
       entity_type IN ('person', 'organization', 'location', 'product', 'event', 
                      'concept', 'technology', 'regulation', 'document')
   ),
   status VARCHAR(50) DEFAULT 'active' CHECK (status IN ('active', 'inactive', 'merged', 'archived')),
   primary_category VARCHAR(100),
   subcategories TEXT[],
   description TEXT,
   short_description TEXT,
   aliases TEXT[],
   languages TEXT[],
   properties JSONB,
   external_ids JSONB,
   links JSONB,
   image_url TEXT,
   media_urls JSONB,
   importance_score FLOAT CHECK (importance_score BETWEEN 0 AND 1),
   trending_score FLOAT,
   sentiment_score FLOAT CHECK (sentiment_score BETWEEN -1 AND 1),
   sentiment_keywords TEXT[5],
   mention_count INT DEFAULT 0,
   citation_count INT DEFAULT 0,
   view_count INT DEFAULT 0,
   first_seen_at TIMESTAMPTZ,
   last_seen_at TIMESTAMPTZ,
   peak_mention_date TIMESTAMPTZ,
   created_at TIMESTAMPTZ DEFAULT CURRENT_TIMESTAMP,
   updated_at TIMESTAMPTZ DEFAULT CURRENT_TIMESTAMP,
   UNIQUE(normalized_name, entity_type)
);

CREATE TABLE entities.entity_relationships (
   source_entity_id INT REFERENCES entities.entities(entity_id),
   target_entity_id INT REFERENCES entities.entities(entity_id),
   relationship_type VARCHAR(50) NOT NULL CHECK (
       relationship_type IN ('parent_of', 'child_of', 'affiliate_of', 'member_of',
                           'competitor_of', 'collaborator_with', 'located_in',
                           'manages', 'created_by', 'owns', 'related_to')
   ),
   strength FLOAT CHECK (strength BETWEEN 0 AND 1),
   confidence_score FLOAT CHECK (confidence_score BETWEEN 0 AND 1),
   bidirectional BOOLEAN DEFAULT false,
   valid_from TIMESTAMPTZ,
   valid_until TIMESTAMPTZ,
   properties JSONB,
   citation_urls TEXT[],
   mention_count INT DEFAULT 0,
   last_mentioned_at TIMESTAMPTZ,
   created_at TIMESTAMPTZ DEFAULT CURRENT_TIMESTAMP,
   updated_at TIMESTAMPTZ DEFAULT CURRENT_TIMESTAMP,
   PRIMARY KEY (source_entity_id, target_entity_id, relationship_type),
   CHECK (source_entity_id != target_entity_id)
);

CREATE TABLE entities.entity_mentions (
   mention_id SERIAL PRIMARY KEY,
   entity_id INT REFERENCES entities.entities(entity_id),
   content_type VARCHAR(50) NOT NULL CHECK (
       content_type IN ('article', 'comment', 'social_post', 'video', 'document')
   ),
   content_id INT NOT NULL,
   portal_id INT REFERENCES public.news_portals(portal_id),
   mention_type VARCHAR(50) NOT NULL CHECK (
       mention_type IN ('primary_subject', 'secondary_subject', 'referenced', 
                       'quoted', 'background')
   ),
   context_snippet TEXT,
   context_position JSONB,
   sentiment_score FLOAT CHECK (sentiment_score BETWEEN -1 AND 1),
   importance_score FLOAT CHECK (importance_score BETWEEN 0 AND 1),
   confidence_score FLOAT CHECK (confidence_score BETWEEN 0 AND 1),
   co_mentioned_entities INT[],
   created_at TIMESTAMPTZ DEFAULT CURRENT_TIMESTAMP,
   UNIQUE(entity_id, content_type, content_id, context_position)
);
Continue with more Entity tables?

 Copy
Retry


H
Yes


sql

Copy
CREATE TABLE entities.entity_timeline (
   timeline_id SERIAL PRIMARY KEY,
   entity_id INT REFERENCES entities.entities(entity_id),
   event_type VARCHAR(50) NOT NULL CHECK (
       event_type IN ('created', 'updated', 'merged', 'split', 'relationship_added',
                     'relationship_removed', 'trending', 'significant_mention')
   ),
   event_date TIMESTAMPTZ NOT NULL,
   event_description TEXT,
   importance_score FLOAT CHECK (importance_score BETWEEN 0 AND 1),
   metadata JSONB,
   created_at TIMESTAMPTZ DEFAULT CURRENT_TIMESTAMP
);

CREATE TABLE entities.entity_statistics (
   entity_id INT REFERENCES entities.entities(entity_id),
   date_bucket DATE NOT NULL,
   mention_count INT DEFAULT 0,
   unique_sources_count INT DEFAULT 0,
   view_count INT DEFAULT 0,
   interaction_count INT DEFAULT 0,
   sentiment_score FLOAT CHECK (sentiment_score BETWEEN -1 AND 1),
   importance_score FLOAT,
   trending_score FLOAT,
   top_co_occurrences JSONB,
   peak_hour_mentions INT[],
   created_at TIMESTAMPTZ DEFAULT CURRENT_TIMESTAMP,
   PRIMARY KEY (entity_id, date_bucket)
);

CREATE TABLE entities.entity_merges (
   merge_id SERIAL PRIMARY KEY,
   source_entity_id INT REFERENCES entities.entities(entity_id),
   target_entity_id INT REFERENCES entities.entities(entity_id),
   merge_reason TEXT,
   confidence_score FLOAT CHECK (confidence_score BETWEEN 0 AND 1),
   metadata JSONB,
   merged_at TIMESTAMPTZ DEFAULT CURRENT_TIMESTAMP
);

-- Create indexes for Entities schema
CREATE INDEX idx_entities_type ON entities.entities(entity_type);
CREATE INDEX idx_entities_status ON entities.entities(status);
CREATE INDEX idx_entities_normalized_name ON entities.entities(normalized_name);
CREATE INDEX idx_entities_importance ON entities.entities(importance_score DESC);
CREATE INDEX idx_entities_trending ON entities.entities(trending_score DESC);
CREATE INDEX idx_entities_temporal ON entities.entities(last_seen_at);
CREATE INDEX idx_entities_properties ON entities.entities USING GIN (properties);
CREATE INDEX idx_entities_external_ids ON entities.entities USING GIN (external_ids);
Continue with more indexes and triggers for Entities schema?

 Copy
Retry


H
Yes


sql

Copy
-- Entity Relationship Indexes
CREATE INDEX idx_entity_relationships_temporal 
   ON entities.entity_relationships(valid_from, valid_until);
CREATE INDEX idx_entity_relationships_strength 
   ON entities.entity_relationships(strength DESC);

-- Entity Mentions Indexes
CREATE INDEX idx_entity_mentions_content 
   ON entities.entity_mentions(content_type, content_id);
CREATE INDEX idx_entity_mentions_temporal 
   ON entities.entity_mentions(created_at);
CREATE INDEX idx_entity_mentions_importance 
   ON entities.entity_mentions(importance_score DESC);

-- Entity Timeline Indexes
CREATE INDEX idx_entity_timeline_date 
   ON entities.entity_timeline(event_date);
CREATE INDEX idx_entity_timeline_type 
   ON entities.entity_timeline(event_type);

-- Entity Statistics Indexes
CREATE INDEX idx_entity_statistics_date 
   ON entities.entity_statistics(date_bucket);
CREATE INDEX idx_entity_statistics_trending 
   ON entities.entity_statistics(trending_score DESC);

-- Full Text Search Index
CREATE INDEX idx_entities_text_search ON entities.entities 
   USING GIN (to_tsvector('english', 
       coalesce(name, '') || ' ' || 
       coalesce(description, '') || ' ' || 
       coalesce(array_to_string(aliases, ' '), '') || ' ' ||
       coalesce(short_description, '')
   ));

-- Triggers
CREATE TRIGGER update_entity_updated_at
   BEFORE UPDATE ON entities.entities
   FOR EACH ROW
   EXECUTE FUNCTION update_updated_at_column();

CREATE TRIGGER update_entity_relationships_updated_at
   BEFORE UPDATE ON entities.entity_relationships
   FOR EACH ROW
   EXECUTE FUNCTION update_updated_at_column();
Continue with Comments schema?

 Copy
Retry


H
Yes


sql

Copy
CREATE SCHEMA IF NOT EXISTS comments;

CREATE TABLE comments.comments (
   comment_id TEXT PRIMARY KEY,
   article_id INT NOT NULL,
   portal_id INT REFERENCES public.news_portals(portal_id),
   content TEXT NOT NULL,
   content_html TEXT,
   language_code VARCHAR(10),
   author_id TEXT,
   author_name TEXT,
   author_verified BOOLEAN DEFAULT false,
   author_metadata JSONB,
   parent_comment_id TEXT REFERENCES comments.comments(comment_id),
   root_comment_id TEXT,
   reply_level INT DEFAULT 0,
   thread_path LTREE,
   likes_count INT DEFAULT 0,
   dislikes_count INT DEFAULT 0,
   replies_count INT DEFAULT 0,
   share_count INT DEFAULT 0,
   engagement_score FLOAT,
   sentiment_score FLOAT CHECK (sentiment_score BETWEEN -1 AND 1),
   sentiment_keywords TEXT[5],
   sentiment_magnitude FLOAT,
   topic_keywords TEXT[],
   named_entities JSONB,
   topic_categories TEXT[],
   is_spam BOOLEAN DEFAULT false,
   toxicity_score FLOAT,
   quality_score FLOAT CHECK (quality_score BETWEEN 0 AND 1),
   platform_specific_data JSONB,
   posted_at TIMESTAMPTZ NOT NULL,
   edited_at TIMESTAMPTZ,
   last_activity_at TIMESTAMPTZ,
   created_at TIMESTAMPTZ DEFAULT CURRENT_TIMESTAMP,
   updated_at TIMESTAMPTZ DEFAULT CURRENT_TIMESTAMP
);

CREATE TABLE comments.article_comment_stats (
   article_id INT NOT NULL,
   portal_id INT REFERENCES public.news_portals(portal_id),
   total_comments_count INT DEFAULT 0,
   top_level_comments_count INT DEFAULT 0,
   reply_comments_count INT DEFAULT 0,
   total_likes_count INT DEFAULT 0,
   total_dislikes_count INT DEFAULT 0,
   total_shares_count INT DEFAULT 0,
   engagement_rate FLOAT,
   overall_sentiment_score FLOAT,
   sentiment_distribution JSONB,
   top_sentiment_keywords TEXT[10],
   top_discussion_topics TEXT[],
   topic_distribution JSONB,
   key_entities JSONB,
   avg_comment_quality FLOAT,
   spam_comment_ratio FLOAT,
   toxic_comment_ratio FLOAT,
   peak_activity_periods JSONB,
   last_comment_at TIMESTAMPTZ,
   created_at TIMESTAMPTZ DEFAULT CURRENT_TIMESTAMP,
   updated_at TIMESTAMPTZ DEFAULT CURRENT_TIMESTAMP,
   PRIMARY KEY (article_id, portal_id)
);
Continue with more Comments schema tables?

 Copy
Retry


H
Yes


sql

Copy
CREATE TABLE comments.comment_topics (
   comment_id TEXT REFERENCES comments.comments(comment_id),
   topic_id INT REFERENCES topics.topics(topic_id),
   relevance_score FLOAT CHECK (relevance_score BETWEEN 0 AND 1),
   sentiment_score FLOAT,
   confidence_score FLOAT CHECK (confidence_score BETWEEN 0 AND 1),
   context_summary TEXT,
   key_phrases TEXT[],
   relationship_type VARCHAR(50) CHECK (
       relationship_type IN (
           'direct_discussion',
           'reference',
           'tangential',
           'comparison'
       )
   ),
   created_at TIMESTAMPTZ DEFAULT CURRENT_TIMESTAMP,
   PRIMARY KEY (comment_id, topic_id)
);

CREATE TABLE comments.comment_trends (
   trend_id SERIAL PRIMARY KEY,
   article_id INT NOT NULL,
   portal_id INT REFERENCES public.news_portals(portal_id),
   window_start TIMESTAMPTZ NOT NULL,
   window_duration INTERVAL NOT NULL,
   comment_velocity FLOAT,
   engagement_velocity FLOAT,
   sentiment_trend FLOAT,
   trending_keywords TEXT[],
   trending_topics TEXT[],
   hot_comments TEXT[],
   created_at TIMESTAMPTZ DEFAULT CURRENT_TIMESTAMP,
   UNIQUE (article_id, portal_id, window_start)
);

-- Indexes for Comments schema
CREATE INDEX idx_comments_article ON comments.comments(article_id, portal_id);
CREATE INDEX idx_comments_hierarchy ON comments.comments(parent_comment_id, root_comment_id);
CREATE INDEX idx_comments_path ON comments.comments USING GIST (thread_path);
CREATE INDEX idx_comments_temporal ON comments.comments(posted_at);
CREATE INDEX idx_comments_engagement ON comments.comments(engagement_score DESC);
CREATE INDEX idx_comments_sentiment ON comments.comments(sentiment_score);
CREATE INDEX idx_comments_quality ON comments.comments(quality_score DESC);
CREATE INDEX idx_comments_author ON comments.comments(author_id);
CREATE INDEX idx_comments_content_search ON comments.comments USING gin(to_tsvector('english', content));

CREATE INDEX idx_comment_stats_temporal ON comments.article_comment_stats(last_comment_at);
CREATE INDEX idx_comment_stats_engagement ON comments.article_comment_stats(engagement_rate DESC);
CREATE INDEX idx_comment_topics_relevance ON comments.comment_topics(relevance_score DESC);
CREATE INDEX idx_comment_topics_sentiment ON comments.comment_topics(sentiment_score);
CREATE INDEX idx_comment_trends_temporal ON comments.comment_trends(window_start, window_duration);
CREATE INDEX idx_comment_trends_velocity ON comments.comment_trends(comment_velocity DESC);

-- Triggers for Comments schema
CREATE TRIGGER update_comment_updated_at
   BEFORE UPDATE ON comments.comments
   FOR EACH ROW
   EXECUTE FUNCTION update_updated_at_column();

CREATE TRIGGER update_comment_stats_updated_at
   BEFORE UPDATE ON comments.article_comment_stats
   FOR EACH ROW
   EXECUTE FUNCTION update_updated_at_column();
Continue with Social Media schema?

 Copy
Retry


H
Yes


sql

Copy
CREATE SCHEMA IF NOT EXISTS social;

CREATE TABLE social.platforms (
  platform_id SERIAL PRIMARY KEY,
  name VARCHAR(50) NOT NULL UNIQUE,
  api_version VARCHAR(50),
  enabled BOOLEAN DEFAULT true,
  rate_limits JSONB,
  auth_config JSONB,
  feature_flags JSONB,
  metrics_mapping JSONB,
  created_at TIMESTAMPTZ DEFAULT CURRENT_TIMESTAMP,
  updated_at TIMESTAMPTZ DEFAULT CURRENT_TIMESTAMP
);

CREATE TABLE social.posts (
  post_id TEXT PRIMARY KEY,
  platform_id INT REFERENCES social.platforms(platform_id),
  article_id INT NOT NULL,
  portal_id INT REFERENCES public.news_portals(portal_id),
  content TEXT NOT NULL,
  content_type VARCHAR(50) CHECK (
      content_type IN ('text', 'image', 'video', 'link', 'poll', 'mixed')
  ),
  language_code VARCHAR(10),
  urls TEXT[],
  media_urls JSONB,
  hashtags TEXT[],
  mentions TEXT[],
  author_platform_id TEXT,
  author_username TEXT,
  author_display_name TEXT,
  author_verified BOOLEAN DEFAULT false,
  author_metrics JSONB,
  likes_count INT DEFAULT 0,
  shares_count INT DEFAULT 0,
  replies_count INT DEFAULT 0,
  quote_count INT DEFAULT 0,
  bookmark_count INT DEFAULT 0,
  click_count INT DEFAULT 0,
  impression_count INT DEFAULT 0,
  engagement_rate FLOAT,
  viral_score FLOAT,
  potential_reach INT,
  actual_reach INT,
  sentiment_score FLOAT CHECK (sentiment_score BETWEEN -1 AND 1),
  sentiment_keywords TEXT[5],
  topic_categories TEXT[],
  named_entities JSONB,
  platform_specific_data JSONB,
  monetization_data JSONB,
  posted_at TIMESTAMPTZ NOT NULL,
  peak_activity_at TIMESTAMPTZ,
  last_updated_at TIMESTAMPTZ,
  created_at TIMESTAMPTZ DEFAULT CURRENT_TIMESTAMP,
  updated_at TIMESTAMPTZ DEFAULT CURRENT_TIMESTAMP
);
Continue with more Social Media tables?

 Copy
Retry


H
Yes


sql

Copy
CREATE TABLE social.interactions (
  interaction_id TEXT PRIMARY KEY,
  platform_id INT REFERENCES social.platforms(platform_id),
  post_id TEXT REFERENCES social.posts(post_id),
  parent_interaction_id TEXT REFERENCES social.interactions(interaction_id),
  thread_path LTREE,
  interaction_depth INT DEFAULT 0,
  interaction_type VARCHAR(50) CHECK (
      interaction_type IN ('reply', 'quote', 'mention', 'share')
  ),
  content TEXT,
  language_code VARCHAR(10),
  author_platform_id TEXT,
  author_username TEXT,
  author_verified BOOLEAN DEFAULT false,
  author_metrics JSONB,
  likes_count INT DEFAULT 0,
  replies_count INT DEFAULT 0,
  engagement_score FLOAT,
  sentiment_score FLOAT CHECK (sentiment_score BETWEEN -1 AND 1),
  sentiment_keywords TEXT[5],
  topic_relevance JSONB,
  quality_score FLOAT,
  platform_specific_data JSONB,
  posted_at TIMESTAMPTZ NOT NULL,
  created_at TIMESTAMPTZ DEFAULT CURRENT_TIMESTAMP,
  updated_at TIMESTAMPTZ DEFAULT CURRENT_TIMESTAMP
);

CREATE TABLE social.article_social_metrics (
  article_id INT NOT NULL,
  portal_id INT REFERENCES public.news_portals(portal_id),
  platform_id INT REFERENCES social.platforms(platform_id),
  total_posts_count INT DEFAULT 0,
  unique_authors_count INT DEFAULT 0,
  total_likes_count INT DEFAULT 0,
  total_shares_count INT DEFAULT 0,
  total_replies_count INT DEFAULT 0,
  total_impressions_count INT DEFAULT 0,
  avg_engagement_rate FLOAT,
  engagement_velocity FLOAT,
  viral_coefficient FLOAT,
  total_potential_reach INT,
  total_actual_reach INT,
  reach_efficiency FLOAT,
  audience_demographics JSONB,
  influencer_participation JSONB,
  overall_sentiment_score FLOAT,
  sentiment_distribution JSONB,
  top_sentiment_keywords TEXT[10],
  trending_hashtags TEXT[],
  key_discussion_topics TEXT[],
  viral_content_pieces JSONB,
  first_mention_at TIMESTAMPTZ,
  peak_activity_at TIMESTAMPTZ,
  last_activity_at TIMESTAMPTZ,
  hourly_engagement_data JSONB,
  daily_trend_data JSONB,
  created_at TIMESTAMPTZ DEFAULT CURRENT_TIMESTAMP,
  updated_at TIMESTAMPTZ DEFAULT CURRENT_TIMESTAMP,
  PRIMARY KEY (article_id, portal_id, platform_id)
);
Continue with more Social Media tables and indexes?

 Copy
Retry


H
Yes


sql

Copy
CREATE TABLE social.trending_metrics (
  trend_id SERIAL PRIMARY KEY,
  article_id INT NOT NULL,
  platform_id INT REFERENCES social.platforms(platform_id),
  window_start TIMESTAMPTZ NOT NULL,
  window_duration INTERVAL NOT NULL,
  posts_velocity FLOAT,
  engagement_velocity FLOAT,
  sentiment_velocity FLOAT,
  trending_hashtags TEXT[],
  trending_topics TEXT[],
  viral_posts TEXT[],
  viral_coefficient FLOAT,
  amplification_rate FLOAT,
  created_at TIMESTAMPTZ DEFAULT CURRENT_TIMESTAMP,
  UNIQUE (article_id, platform_id, window_start)
);

-- Social Media Indexes
CREATE INDEX idx_posts_article ON social.posts(article_id, portal_id);
CREATE INDEX idx_posts_platform ON social.posts(platform_id, posted_at);
CREATE INDEX idx_posts_engagement ON social.posts(engagement_rate DESC);
CREATE INDEX idx_posts_temporal ON social.posts(posted_at, last_updated_at);
CREATE INDEX idx_posts_viral ON social.posts(viral_score DESC);
CREATE INDEX idx_posts_text_search ON social.posts USING GIN (to_tsvector('english', content));

CREATE INDEX idx_interactions_post ON social.interactions(post_id);
CREATE INDEX idx_interactions_thread ON social.interactions USING GIST (thread_path);
CREATE INDEX idx_interactions_temporal ON social.interactions(posted_at);
CREATE INDEX idx_interactions_author ON social.interactions(author_platform_id);
CREATE INDEX idx_interactions_text_search ON social.interactions USING GIN (to_tsvector('english', content));

CREATE INDEX idx_metrics_temporal ON social.article_social_metrics(last_activity_at);
CREATE INDEX idx_metrics_engagement ON social.article_social_metrics(avg_engagement_rate DESC);
CREATE INDEX idx_metrics_viral ON social.article_social_metrics(viral_coefficient DESC);

CREATE INDEX idx_trends_temporal ON social.trending_metrics(window_start);
CREATE INDEX idx_trends_velocity ON social.trending_metrics(engagement_velocity DESC);

-- Triggers
CREATE TRIGGER update_platform_updated_at
  BEFORE UPDATE ON social.platforms
  FOR EACH ROW EXECUTE FUNCTION update_updated_at_column();

CREATE TRIGGER update_post_updated_at
  BEFORE UPDATE ON social.posts
  FOR EACH ROW EXECUTE FUNCTION update_updated_at_column();

CREATE TRIGGER update_interaction_updated_at
  BEFORE UPDATE ON social.interactions
  FOR EACH ROW EXECUTE FUNCTION update_updated_at_column();

CREATE TRIGGER update_metrics_updated_at
  BEFORE UPDATE ON social.article_social_metrics
  FOR EACH ROW EXECUTE FUNCTION update_updated_at_column();
Continue with Analysis schema?

 Copy
Retry


H
Yes


sql

Copy
CREATE SCHEMA IF NOT EXISTS analysis;

CREATE TABLE analysis.sentiment_lexicon (
  word_id SERIAL PRIMARY KEY,
  word VARCHAR(255) NOT NULL UNIQUE,
  language_code VARCHAR(10) NOT NULL DEFAULT 'en',
  base_score FLOAT NOT NULL CHECK (base_score BETWEEN -1 AND 1),
  intensity_multiplier FLOAT DEFAULT 1.0,
  context_modifiers JSONB,
  part_of_speech VARCHAR(50),
  domain_specific_scores JSONB,
  synonyms TEXT[],
  antonyms TEXT[],
  last_updated_at TIMESTAMPTZ,
  created_at TIMESTAMPTZ DEFAULT CURRENT_TIMESTAMP
);

CREATE TABLE analysis.keywords (
  keyword_id SERIAL PRIMARY KEY,
  keyword VARCHAR(255) NOT NULL,
  normalized_form VARCHAR(255) NOT NULL,
  language_code VARCHAR(10) NOT NULL DEFAULT 'en',
  keyword_type VARCHAR(50) CHECK (
      keyword_type IN ('topic', 'entity', 'event', 'technical', 'industry', 'generic')
  ),
  category VARCHAR(100),
  subcategories TEXT[],
  importance_score FLOAT CHECK (importance_score BETWEEN 0 AND 1),
  domain_relevance JSONB,
  related_keywords TEXT[],
  parent_keywords TEXT[],
  child_keywords TEXT[],
  cooccurring_keywords JSONB,
  occurrence_count INT DEFAULT 0,
  last_seen_at TIMESTAMPTZ,
  trending_score FLOAT,
  created_at TIMESTAMPTZ DEFAULT CURRENT_TIMESTAMP,
  updated_at TIMESTAMPTZ DEFAULT CURRENT_TIMESTAMP,
  UNIQUE(normalized_form, language_code)
);

CREATE TABLE analysis.content_analysis (
  content_id SERIAL PRIMARY KEY,
  source_type VARCHAR(50) NOT NULL CHECK (
      source_type IN ('article', 'comment', 'social_post', 'title', 'summary')
  ),
  source_id INT NOT NULL,
  portal_id INT REFERENCES public.news_portals(portal_id),
  content_length INT,
  language_code VARCHAR(10),
  content_hash TEXT,
  readability_score FLOAT,
  complexity_score FLOAT,
  technical_density FLOAT,
  overall_sentiment_score FLOAT CHECK (sentiment_score BETWEEN -1 AND 1),
  sentiment_magnitude FLOAT,
  sentiment_aspects JSONB,
  emotion_scores JSONB,
  extracted_keywords TEXT[],
  keyword_relevance JSONB,
  key_phrases TEXT[],
  main_topics TEXT[],
  topic_distribution JSONB,
  topic_coherence_score FLOAT,
  named_entities JSONB,
  entity_relationships JSONB,
  grammar_quality FLOAT,
  style_metrics JSONB,
  language_variety JSONB,
  context_tags TEXT[],
  reference_citations JSONB,
  external_links JSONB,
  analyzed_at TIMESTAMPTZ DEFAULT CURRENT_TIMESTAMP,
  updated_at TIMESTAMPTZ DEFAULT CURRENT_TIMESTAMP,
  UNIQUE(source_type, source_id)
);
Continue with more Analysis tables?

 Copy
Retry


H
Yes


sql

Copy
CREATE TABLE analysis.content_statistics (
  stat_id SERIAL PRIMARY KEY,
  source_type VARCHAR(50) NOT NULL,
  source_id INT NOT NULL,
  time_bucket TIMESTAMPTZ NOT NULL,
  bucket_duration INTERVAL NOT NULL,
  word_count INT,
  unique_words_count INT,
  sentence_count INT,
  paragraph_count INT,
  view_count INT,
  read_time_avg FLOAT,
  completion_rate FLOAT,
  bounce_rate FLOAT,
  content_velocity FLOAT,
  update_frequency FLOAT,
  freshness_score FLOAT,
  keyword_density JSONB,
  trending_keywords TEXT[],
  keyword_velocity JSONB,
  topic_shifts JSONB,
  topic_emergence JSONB,
  topic_decay JSONB,
  created_at TIMESTAMPTZ DEFAULT CURRENT_TIMESTAMP,
  UNIQUE(source_type, source_id, time_bucket)
);

CREATE TABLE analysis.semantic_relationships (
  relationship_id SERIAL PRIMARY KEY,
  source_term VARCHAR(255) NOT NULL,
  target_term VARCHAR(255) NOT NULL,
  relationship_type VARCHAR(50) CHECK (
      relationship_type IN ('synonym', 'antonym', 'hypernym', 'hyponym', 'meronym', 'holonym')
  ),
  strength FLOAT CHECK (strength BETWEEN 0 AND 1),
  confidence_score FLOAT CHECK (confidence_score BETWEEN 0 AND 1),
  context_vector JSONB,
  source_count INT DEFAULT 0,
  last_seen_at TIMESTAMPTZ,
  created_at TIMESTAMPTZ DEFAULT CURRENT_TIMESTAMP,
  UNIQUE(source_term, target_term, relationship_type)
);

-- Indexes
CREATE INDEX idx_lexicon_word ON analysis.sentiment_lexicon(word);
CREATE INDEX idx_lexicon_language ON analysis.sentiment_lexicon(language_code);
CREATE INDEX idx_lexicon_score ON analysis.sentiment_lexicon(base_score);

CREATE INDEX idx_keywords_normalized ON analysis.keywords(normalized_form);
CREATE INDEX idx_keywords_type ON analysis.keywords(keyword_type, category);
CREATE INDEX idx_keywords_importance ON analysis.keywords(importance_score DESC);
CREATE INDEX idx_keywords_trending ON analysis.keywords(trending_score DESC);

CREATE INDEX idx_content_source ON analysis.content_analysis(source_type, source_id);
CREATE INDEX idx_content_sentiment ON analysis.content_analysis(overall_sentiment_score);
CREATE INDEX idx_content_temporal ON analysis.content_analysis(analyzed_at);

CREATE INDEX idx_stats_temporal ON analysis.content_statistics(time_bucket);
CREATE INDEX idx_stats_source ON analysis.content_statistics(source_type, source_id);

CREATE INDEX idx_semantic_terms ON analysis.semantic_relationships(source_term, target_term);
CREATE INDEX idx_semantic_type ON analysis.semantic_relationships(relationship_type);

CREATE INDEX idx_keywords_text_search ON analysis.keywords 
  USING GIN (to_tsvector('english', keyword || ' ' || coalesce(array_to_string(related_keywords, ' '), '')));

-- Triggers
CREATE TRIGGER update_keyword_updated_at
  BEFORE UPDATE ON analysis.keywords
  FOR EACH ROW EXECUTE FUNCTION update_updated_at_column();

CREATE TRIGGER update_content_analysis_updated_at
  BEFORE UPDATE ON analysis.content_analysis
  FOR EACH ROW EXECUTE FUNCTION update_updated_at_column();
Should I continue with any remaining schema components?

 Copy
Retry


H
Yes


sql

Copy
-- Content trends view
CREATE OR REPLACE VIEW analysis.content_trends AS
SELECT 
  source_type,
  date_trunc('hour', analyzed_at) as time_bucket,
  count(*) as analysis_count,
  avg(overall_sentiment_score) as avg_sentiment,
  avg(complexity_score) as avg_complexity,
  jsonb_object_agg(
      DISTINCT topic_distribution ORDER BY topic_distribution DESC
      LIMIT 10
  ) as trending_topics
FROM analysis.content_analysis
GROUP BY 
  source_type,
  date_trunc('hour', analyzed_at);

-- General performance indexes
CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_all_created_at 
   ON public.news_portals(created_at);

-- Partitioning function for large tables
CREATE OR REPLACE FUNCTION create_time_partitions()
RETURNS void AS $$
DECLARE
   start_date DATE := '2024-01-01';
   end_date DATE := '2025-12-31';
   interval_months INT := 3;
   current_date DATE := start_date;
BEGIN
   WHILE current_date < end_date LOOP
       -- Create partitions for events.timeline_entries
       EXECUTE format(
           'CREATE TABLE IF NOT EXISTS events.timeline_entries_%s 
            PARTITION OF events.timeline_entries 
            FOR VALUES FROM (%L) TO (%L)',
           to_char(current_date, 'YYYY_MM'),
           current_date,
           current_date + interval '3 months'
       );
       
       -- Create partitions for comments.comments
       EXECUTE format(
           'CREATE TABLE IF NOT EXISTS comments.comments_%s 
            PARTITION OF comments.comments 
            FOR VALUES FROM (%L) TO (%L)',
           to_char(current_date, 'YYYY_MM'),
           current_date,
           current_date + interval '3 months'
       );
       
       current_date := current_date + interval '3 months';
   END LOOP;
END;
$$ LANGUAGE plpgsql;

-- Statistics materialized view
CREATE MATERIALIZED VIEW analysis.content_statistics_mv AS
SELECT 
   source_type,
   date_trunc('day', time_bucket) as day,
   avg(word_count) as avg_word_count,
   avg(view_count) as avg_view_count,
   avg(completion_rate) as avg_completion_rate
FROM analysis.content_statistics
GROUP BY source_type, date_trunc('day', time_bucket)
WITH DATA;

CREATE UNIQUE INDEX ON analysis.content_statistics_mv (source_type, day);

-- Refresh function for materialized views
CREATE OR REPLACE FUNCTION refresh_materialized_views()
RETURNS void AS $$
BEGIN
   REFRESH MATERIALIZED VIEW CONCURRENTLY analysis.content_statistics_mv;
END;
$$ LANGUAGE plpgsql;
 Copy
Retry


H
Are you done?


Let me complete the schema with the final components:

sql

Copy
-- Comment validation trigger
CREATE OR REPLACE FUNCTION validate_comment_references()
RETURNS TRIGGER AS $$
BEGIN
    -- Validate article existence
    IF NOT EXISTS (
        SELECT 1 
        FROM public.news_portals p 
        WHERE p.portal_id = NEW.portal_id
    ) THEN
        RAISE EXCEPTION 'Invalid portal_id';
    END IF;

    -- Validate parent comment if exists
    IF NEW.parent_comment_id IS NOT NULL AND NOT EXISTS (
        SELECT 1 
        FROM comments.comments 
        WHERE comment_id = NEW.parent_comment_id
    ) THEN
        RAISE EXCEPTION 'Invalid parent_comment_id';
    END IF;

    RETURN NEW;
END;
$$ LANGUAGE plpgsql;

CREATE TRIGGER validate_comment_references
    BEFORE INSERT OR UPDATE ON comments.comments
    FOR EACH ROW
    EXECUTE FUNCTION validate_comment_references();

-- Final system-wide indexes
CREATE INDEX CONCURRENTLY IF NOT EXISTS idx_all_updated_at 
    ON public.news_portals(updated_at);

ANALYZE public.news_portals;
ANALYZE events.events;
ANALYZE topics.topics;
ANALYZE entities.entities;
ANALYZE comments.comments;
ANALYZE social.posts;
ANALYZE analysis.content_analysis;
Now the schema is complete. All necessary tables, indexes, triggers, views, and validation functions are in place.

 Copy
Retry


